# -*- coding: utf-8 -*-
"""Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14GaKmLEM88DUjg1FUUETXzolNSD7Vte0
"""

pip install nltk spacy textblob vaderSentiment afinn

pip install python-docx

import docx
import os

def read_word_file(file_path):
    """Reads text from a Word document and returns it as a string."""
    if not os.path.exists(file_path):
        return "Error: File not found!"

    try:
        doc = docx.Document(file_path)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text
    except Exception as e:
        return f"Error reading file: {e}"

# Replace with actual file path
file_path = "/content/James Rhee.docx"

# Debugging: Check if file exists
if os.path.exists(file_path):
    print("✅ File found! Processing...")
else:
    print("❌ File not found. Check the path!")

# Read the document
speech_text = read_word_file(file_path)

# Display first 500 characters
print(speech_text[:1000000])

import re
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

def preprocess_text(text):
  text=text.lower()
  text = re.sub(r'[^\w\s]', '', text)  # Removing punctuation
  words = text.split()
  words = [word for word in words if word not in stopwords.words('english')]  # Removing stopwords
  return " ".join(words)

cleaned_text = preprocess_text(speech_text)
print(cleaned_text[:100000])

pip install vaderSentiment afinn

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from afinn import Afinn

# VADER Sentiment
vader_analyzer = SentimentIntensityAnalyzer()
vader_scores = vader_analyzer.polarity_scores(cleaned_text)
print("VADER Sentiment Scores:", vader_scores)

# AFINN Sentiment
afinn = Afinn()
afinn_score = afinn.score(cleaned_text)
print("AFINN Score:", afinn_score)

import pandas as pd

# Load NRC Emotion Lexicon
nrc = pd.read_csv("/content/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt", delimiter='\t', header=None, names=["word", "emotion", "association"])
nrc = nrc[nrc["association"] == 1]  # Keep only associated words

# Find words in text that match NRC lexicon
speech_words = set(cleaned_text.split())
emotion_counts = nrc[nrc["word"].isin(speech_words)]["emotion"].value_counts()

print("Emotion Distribution in Speech:\n", emotion_counts)

from collections import Counter

word_freq = Counter(cleaned_text.split())
print("Most Common Words:", word_freq.most_common(10))

from docx import Document

def create_word_report(results, filename="CEO_Lexicon_Analysis.docx"):
    doc = Document()
    doc.add_heading("Lexicon Analysis of CEO's Speech", level=1)

    for key, value in results.items():
        doc.add_heading(key, level=2)
        doc.add_paragraph(str(value))

    doc.save(filename)

# Example Results
results = {
    "VADER Sentiment Scores": vader_scores,
    "AFINN Sentiment Score": afinn_score,
    "Emotion Distribution": emotion_counts.to_dict(),
    "Most Frequent Words": word_freq.most_common(10)
}

create_word_report(results)